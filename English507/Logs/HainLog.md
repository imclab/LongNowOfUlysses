# Some thoughts and questions regarding Week 7 readings  

25 February, 2013  

Re: Moretti's ["Conjectures on World Literature"](http://newleftreview.org/II/1/franco-moretti-conjectures-on-world-literature)  

Between Moretti, Ramsay, Manovitch, and to some extent Samuels/ McGann, this is the first I've ever really read much about "distance reading" and I wonder how much of its emergence as a critical practice has to do with technological innovations. 
This is especially interesting to think about with respect to Moretti, who doesn't really talk explicitly about computers in his critical practices, but who -- like Manovitch -- is very much interested in the kinds of huge sample sizes that only computers can really deal with.
So how new is distance reading, and how closely does its emergence correspond with developments in computation and the web? Moretti shows parenthetically how close reading has dominated "from the new criticism to deconstruction," and explains its domination in ideological terms: "you invest so much in individual texts *only* if you think that very few of them matter" (57). But how much does the emergence of distance reading owe to critics actually overcoming this ideology versus the development of computer programs and availability of data on the web?
As is probably clear by my entries on [Bloom Vision](https://github.com/uvicmakerlab/LongNowOfUlysses/blob/master/English507/NeedsAssessment/HainNeeds.md), I'm interested in the relationships between technological innovations and the emerging paradigms, art forms, and disciplines they enable (traditionally, I've focused on cinema, photography, increasingly architecture; in the context of 507 and my work at the Maker Lab, I'm trying to adapt this approach to digital technologies). So, what about distance reading? 
It's not something I practice, or that I'm even particularly familiar with, but these articles -- especially those, like Moretti's, that don't explicitly talk about computers -- have led me to start thinking about the technologies that have enabled the emergence of what seems to me a fairly recent development in critical practice. 
All the more so, because the computer is conspicuously absent here.  

Re: Ramsay and ["Algorithmic Criticism"](http://nora.lis.uiuc.edu:3030/companion/view?docId=blackwell/9781405148641/9781405148641.xml&doc.view=print&chunk.id=ss1-6-7&toc.depth=1&toc.id=0)  

I'm moderately blown away by ![table 26.2](https://www.dropbox.com/s/xy77o9n5czztg1v/Table%2026.2.png); Ramsay's right to point out that this kind of information does little more than confirm what a reader familiar with *The Waves* would already know, but I'm blown away by how accurate a confirmation it offers.
I wasn't expecting to enjoy an article titled "Algorithmic Criticism," but Ramsay is a *really* good writer. Some highlights for me:  

"In some sense, humanistic discourse seems to lack methodology; it cannot describe the ground rules of engagement, the precise means of verification, or even the parameters of its subject matter."  

"Literary critical interpretation is not just a qualitative matter, but an insistently subjective manner of engagement."  

"We would do better to recognize that a scientific literary criticism would cease to be criticism."  

"The critic who endeavors to put forth a 'reading,' puts forth not the text, but a new text in which the data has been paraphrased, elaborated, selected, truncated, and transduced."

As in the Woolf table, there's nothing really new here, but just like the Woolf table, presentation (in this case, phrasing) is strikingly apt. 

Re: Samuels and McGann: ["Deformance and Interpretation"](http://muse.jhu.edu/login?auth=0&type=summary&url=/journals/new_literary_history/v030/30.1mcgann.html)
  
I like to think I'm usually, if not always, receptive to new models of criticism, especially those that emphasize practice, but I found myself more convinced by (and interested in) McGann and Samuels' later point -- that all criticism has a deformative aspect -- than some of the material on deformative criticism proper.
From McGann and Samuels' initial examples -- forgery and  "mistaken and deviant readings produced, for example, by students unaware of an ignorance in their historical or linguistic understanding" (35) -- I found myself skeptical of the benefits of deformative criticism in practice: what would a positive or useful deformative criticism look like?
And I was surprised to find the extent to which the examples of deformation in criticism of Wallace Stevens' poetry relied on traditional (normative, to use Samuels/ McGann's term) expository interpretation. But in a way, I guess this works to underline their illuminating point that deformation is a factor in all critical interpretation.
What I found most interesting was the way in which Samuels and Mcgann show the interrelation between genre, or mode in writing, and the types of interpretation associated with it (i.e. prose taking on a scientific function, which is historically situated, contributing to our understanding and use of prose as always expository). If "Criticism (scholarship as well as interpretation) tends to imagine itself as an informative rather than a deformative activity" (33), to what extent are the modes of expository prose (in general) and essay-writing (in particular) responsible for the types of criticisms we perform?
What genres, media, methodologies *etc.* might be better suited to doing the kind of criticism McGann and Samuels outline here? And how might DH-tools allow for greater possibilities for deformative criticism?

Re: Manovitch and [Cultural Analytics](http://www.manovich.net/cultural_analytics.pdf)  

I'm not sure I understand the obsession with size and scale (big data, big screens) nor the apparent imperative on the visual here. Cultures are expressed in a variety of forms; is Manovitch's insistence on strictly visual expressions of culture hegemonic in some way?   

What is potentially lost in "thinking of culture as data... that can be mined and visualized"? The expression "mining" for me suggests a kind of appropriation, and begs the question of purpose or intent: who will use this cultural "data" and to what kinds of use? This gets a little scary in the section on "possible commercial applications": "Cultural Analytics should be of interest to providers of media metrics, trend forecasters, social media companies and, in principle, *all big media companies and publishers*."     

I do, however, like the gesture of situating the project of Cultural Analytics into a history of technologies not only influencing cultures, but creating new disciplines and modes of cultural analysis (from slides to art history; from projectors to film studies). 

# Data Model

12 February, 2013

For my data model I've decided to do a simple [spreadsheet](https://docs.google.com/spreadsheet/ccc?key=0Ald25Z0nufmWdHUyVUdYVWIzY2VWZUJpdklrT1dFRWc#gid=0) to keep track of metadata like file name, type, format, date, and the stereoscope component. 
Initially, my data will just be several images of each stereoscope component, which I'll keep in an open directory (dropbox? Drive?) arranged by component type; after that I'm going to start sticthing the images of each component into 3D models that can be printed and then assembled.
It's kind of a strange process, because production here actually precedes most of the modelling; in this way, it's like reverse modelling -- like the the exact opposite of modelling in, say, architectural projects (where it would be absurd to build a building and *then* make a scale model).
But at the same time, I'm working from a kit where the components are cut from templates, so there are physical models out there prior to production, prior to assemblage; there's also the fact that the kit is a replica of an unpatented nineteenth-century technology, itself an improved version of earlier stereoscopes, so it's difficult to pin down any sort of originary model.
It's been interesting to start to think generally about models, and about processes of production and reproduction in both digital and non-digital (industrial) environments.
