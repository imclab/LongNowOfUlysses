## Working Title: 

"Ulysses Sonic Ephemeris"

## Project Description:

Thinking about the ephemeral nature of sound, as it is always already engaged in a process of decay, I set out to explore what it means to give new life to past sonic ephemera from Ulysses. An Ephemeris is a book containing tables predicting star positions; working in a similar way the instillation is a collection of sounds that respond to the position of audience members in the space. James Joyce's Ulysses brings everyday ephemera into the novel. Much in the same way, the instillation takes sounds from the excerpts whether they are ambient soundscapes, specific sounds, music referenced in the novel, or readings and brings them back into the everyday.


## Materials:

* Computer with enough power to run Max/MSP runtime (in what may be a fairly demanding   
	patch)
* Soundcard with 8 outs
* Speaker Rig: 8-channel
* Speaker mounts
* Cables
* 2 Xbox Kinects with mounts for ceiling
* Sound samples for patch database: period recordings of music related to the novel, dramatized text, and soundscapes from the excerpts. 

* Plaque to display blurb about the instillation.

## Reference Patches/Projects

Example of project by (http://www.melaniemoellerproductions.com/ "Melanie Möller") that reads audience input to control output:
(https://www.youtube.com/watch?v=44C15RXux3Q "Visual Space: Motion-based interactive installation")

Explanation of Process:

"Visual Space is an interactive system, which uses motion tracking technology to enable users to control video clips, visual effects and sound through hand, head and shoulder movement. The position of different limbs is detected via a Microsoft Xbox Kinect. Tracking data are extracted in Processing and manipulated in Max/MSP Jitter. The application features a customizable interface that allows loading in videos and sound files as well as to select effects. Clips and visual effects can be deselected, changed or linked to different joints at any time. Therefore, Visual Space facilitates motion controlled video mixing in real time, allows for numerous modes of interaction and can be easily customized. I developed this project as part of my MSc in Creative Technologies at De Montfort University, Leicester." 

(http://vimeo.com/9361781 "Ryo Ikeshiro – Pulse Cubes")

## Bibliography: 

Seth Kim Cohen – "In the Blink of an Ear"
Wolfgang Ernst – "Digital Memory and the Archive"
Douglas Kahn – "Noise, Water, Meat"
Jonathan Sterne – "The Sound Studies Reader"
-- "The Audible Paste"
-- "Mp3 The Meaning of a Format"


## Project Definition and Scope:

The instillation reads when a audience member is standing in front of a panel and responds by playing sounds related to that portion of the novel. The sounds are organized into four types: short sounds from excerpts, soundscapes from excerpts, period recordings of music referenced in the novel, or historical readings such as Joyce reading Aeolus in 1924 and the 1982 Bloomsday radio broadcast.

## Project Delivery:

My project will deliver a Max/MSP environment along with a database of sounds. Collaborating with Gabrielle Odowichuk will provide me with a program to take input data from the Kinects and send it to Max. The patch will diffuse the sounds through an 8 channel speaker setup mounted to the ceiling, behind the audience looking at the panels.

## Risks and Constraints:

A risk moving forward is that the patch will require more power than a single computer can provide. Prior to beta testing it is difficult to estimate what the experience will be like if there is a person at each panel opening all 17 feeds of audio. As I develop and test the patch I will consider what limits need to be built in to avoid cacophony.

## Project Benefit:

My project will work to shape the aural aesthetic experience by helping audience members engage in a meaningful way, hopefully functioning as something more than passing ephemera.

## Deadlines/Milestones

I will have the file architectural, sounds, and dumby mock-ups of the patch completed in my portfolio for April 16th. The patch will be completed, along with Gabrielle's contribution, by May 1 and will be tested before being mounted in the space around May 15th.

## Support:

I am collaborating with Gabrielle Odowichuk on the Kinect side of things. Once the patch reaches the beta testing stage after May 1st it will be helpful to mount the project to work out any bugs that may arise before moving into the library.

## Project Outcomes:

I hope to have the piece achieve a level of audience engagement beyond passive listening, where people are provoked to think about sound in the context of the novel and the exhibit. It is important to me that the sound not be too overwhelming as to distract from the other elements of the exhibit.

## Learning Goals:

I want to improve my Max coding abilities while exploring the possibilities of interactive sound art.

I want to attempt to create an aesthetic object that enables viewers to think with (or engage with) an exhibit rather than listening passively.

